{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaf1769-56f0-4053-810b-4483bec6305b",
   "metadata": {},
   "source": [
    "# Daily Weather Data EDA and Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceda6cf-c7cd-47ac-931b-37437b4dba79",
   "metadata": {},
   "source": [
    "<b>Importing important packages, getting a view of data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31a04b1a-079a-4058-9ae4-62565d94c9b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'daily_weather_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdaily_weather_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'daily_weather_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"data/raw/daily_weather_data.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ad675-2ad2-4970-9689-c9bac533c373",
   "metadata": {},
   "source": [
    "<b>Initial Observations:\n",
    "<ul><li><u>Redundant Columns:</u> Can most likely remove some unnecessary fields to avoid redundancy and collinearity: sunset, sunrise, weather_code</li>\n",
    "    </ul></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ce6d4-34a8-454f-aa16-464db0d09474",
   "metadata": {},
   "source": [
    "<b>Preliminary Data Analysis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f169fc8-5e15-4d93-a4a3-e8c4e446defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990721e-d4f0-4af4-a705-8d830aa910fd",
   "metadata": {},
   "source": [
    "Date column needs to be transformed to datetime data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2dd27-5e17-4b44-b306-075db3a45c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcd0a0-439c-4afd-998c-158fad8411ad",
   "metadata": {},
   "source": [
    "Dataset has ~10k rows with 18 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711dbe47-b21d-4a41-abd1-36e56433f63c",
   "metadata": {},
   "source": [
    "<b>Data Transformations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183acf24-14be-41f2-ad9f-e34fd7981493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete redundant columns\n",
    "df.drop(columns=['sunset','sunrise','weather_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab25a5-2aa3-4b0f-b4fc-b7ed204128e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to datetime dtype\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S+00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c610cf-789b-4c21-a7eb-c119a1a7060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Week Ending' Field\n",
    "df['Week Ending'] = df['date'] + pd.to_timedelta(6 - df['date'].dt.weekday, unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e4988-1851-4a07-8f45-e48b64762b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242f03d-d2f3-415d-a9f0-2f217a873425",
   "metadata": {},
   "source": [
    "<u>NOTE:</u> First entry (1996 Mar 24) will have only one day as part of the weekly aggregations. Either need to truncate or add more data to make the week aggregation accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abdd897-16fd-494d-a4b9-0c8e7a1e9b7e",
   "metadata": {},
   "source": [
    "<b>Weekly Aggregations</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf9748-f00e-41ff-a6c8-a45f4ffac940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (can alter the aggregating functions as desired)\n",
    "\n",
    "weekly_agg = df.groupby('Week Ending').agg({\n",
    "    'temperature_2m_mean': 'mean',\n",
    "    'temperature_2m_min': 'min',\n",
    "    'temperature_2m_max': 'max',\n",
    "    'apparent_temperature_max': 'max',\n",
    "    'apparent_temperature_min': 'min',\n",
    "    'apparent_temperature_mean': 'mean',\n",
    "    'precipitation_sum': 'sum',\n",
    "    'precipitation_hours': 'sum',\n",
    "    'daylight_duration': 'mean',\n",
    "    'sunshine_duration': 'mean',\n",
    "    'snowfall_sum': 'sum',\n",
    "    'showers_sum': 'sum',\n",
    "    'rain_sum': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc2c48-db4d-46d5-8bc3-73c8b9dee0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcde4c-85d0-4e81-b077-d0cc2e254ba9",
   "metadata": {},
   "source": [
    "### EDA for Weekly Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f8c18-ffd4-44c6-9934-2c157e23042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba1298-3e7e-48a7-9e21-e3040dfe4d5e",
   "metadata": {},
   "source": [
    "<b>Outlier Detection - Weather Values</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82666de9-6fa6-4262-beac-7e8165c0e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df.iloc[:,1:7])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Boxplot of Temperature Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc42f17-5abb-4c11-83ed-f9d7e2146411",
   "metadata": {},
   "source": [
    "<b>Checking Precipitation Sum Accuracy</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a6c01-505e-4c3c-ae93-b54af22c2478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a boolean field to validate the accuracy of the precipitation sum field\n",
    "weekly_agg['precipitation_acc'] = (weekly_agg['precipitation_sum'] == (weekly_agg['showers_sum'] + (weekly_agg['snowfall_sum']*10) + weekly_agg['rain_sum']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64243bbc-ac53-4c56-8c65-7cd0529bd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the ratio between accurate and inaccurate precipitation sums\n",
    "t_f = list(weekly_agg['precipitation_acc'].value_counts())\n",
    "t_f[0] / sum(t_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa5a865-c2c7-4c08-b4da-42845c7632b1",
   "metadata": {},
   "source": [
    "Even with the addition of the showers sum column, the precipitation sum is only 76% accurate. A removal of the column or further investigation may be warranted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ac0f9-9f11-40a0-a3f3-0f26ec841867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis that newer values are more accurate than older values due to potential issues with API's older data\n",
    "weekly_agg.groupby('precipitation_acc').mean()['Week Ending']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ff426-a389-4c8e-b646-d2d6fbe2ac21",
   "metadata": {},
   "source": [
    "<b>Restructuring Precipitation Cols</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405d147-7806-4b71-9913-64008056e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert snowfall sum to mm and compute precipitation sum to only include rain and snowfall\n",
    "weekly_agg['precipitation_sum'] = weekly_agg['rain_sum'] + (weekly_agg['snowfall_sum']*10)\n",
    "weekly_agg.drop('showers_sum', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ecd08-7c6a-4c04-81d9-e093e9df9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting snowfall column to mm to avoid discrepancy\n",
    "weekly_agg['snowfall_sum'] = weekly_agg['snowfall_sum']*10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d33ca-1b4c-4789-8d55-524e53b8a8ed",
   "metadata": {},
   "source": [
    "<b>Store data and preserve datatypes</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4923d-bf37-4fb8-ba70-6188d09db115",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_agg."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
